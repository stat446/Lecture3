---
title: "Lecture 3"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```


\subsection*{Types of Probability Samples}
A **simple random sample (SRS)** of size n is 
	\vfill

- A sample of twenty MSU instructors is selected based on the following scheme: 
\vfill
- STAT 446 students are placed in groups for lab sessions. Students are ordered alphabetically and using a random number generator, the numbers are randomly selected to comprise the first group.
\vfill

A **stratified random sample** is a sample selected by first dividing the population into non-overlapping groups called **strata** and then taking a simple random sample within each stratum. 
\vfill

- The career services staff wants to know if they are adequately meeting the needs of the students they serve. 
\vfill
- A biologist is interested in estimating a deer population total in a small geographic region. The region contains two habitat types which are known to influence deer abundance. From each habitat type, 10 plots are randomly selected to be surveyed.
\vfill
- Note: stratum sample sizes do not have to be equal.
\vfill

A **systematic sample** is a sample in which units are selected in a 
\vfill

- You are a quality engineer at Gore and are testing the quality of newly-produced mittens. You need to take a sample of mittens and test their quality. 
\vfill

Suppose the observation units in a population are grouped into non-overlapping sets called **clusters.** 
\vfill

- You work for the Department of Agriculture and wish to determine the percentage of farmers in the United States who use organic farming techniques. It would be difficult and costly to collect a SRS of systematically sample because both of these sampling designs would require visiting many individual farms that are located far from each other. A convenience sample of farmers from a single county would be biased because farming practices vary from region to region. You decide to select several dozen counties from across the United States and then survey every farmer in each of these selected counties. Each county contains a cluster of farmers and data is collected on every farm within the randomly selected counties (clusters).
\newpage

A **multistage sample** is a sample acquired by 

- A city official is investigating rumors about the landlord of a large apartment building complex. To get an idea of the tenants' opinions about their landlord, the official takes a SRS of buildings in the complex followed by a SRS of apartments from each selected building. From each chosen apartment a resident is interviewed.


\subsection*{Probability Sampling Designs}
Suppose N is the population size. That is, there are N units in the universe or finite population of interest. The N units in the universe are denoted by an index set of labels:
	$\mathcal{U} = \{1,2,3,...,N\}$.
	\vfill
	
From this universe (or population) a sample of n units is to be taken. Let $\mathcal{S}$ represent a sample of n units from $\mathcal{U}$.
\vfill

Associated with each of the N units is a measurable value related to the population characteristic of interest. Let $y_i$ be the value associated with unit $i$, and the population of y-values is $\{y_1,.y_2,...,y_n\}.$
\vfill

Sampling designs that are based on planned randomness are called **probability samples**, and a probability $P(\mathcal{S})$ is assigned to every possible sample $\mathcal{S}$.
\vfill

The probability that unit $i$ will be included in a sample is denoted $\pi_i$ and 

\vfill

Suppose you have a sampling frame with four units and you randomly select two units to sample with a SRS.

- What is the probability of unit # 1 being included in the sample?


\vfill
\newpage
Simulation or more specifically Monte Carlo procedures can also be used to estimate inclusion probabilities.
```{r}
library(dplyr)
set.seed(09042019)
samples <- replicate(10, sample(4,2, replace = F))
samples
find_val <- function(samples, val){
  return(val %in% samples)
}
samples_large <- replicate(1000, sample(4,2, replace = F))

apply(samples_large, 2, find_val,val = 1 ) %>% mean()
```


\subsection*{Inference from Samples}
One goal of sampling is to draw conclusions about a population of interest based on the data collected. This process of drawing conclusions is called **statistical inference**.
\vfill

A **parameter** is a value which describes some characteristic of a population (or possible describes the entire population).
\vfill

A **statistic** is a value that can be computed from the sample data without making use of any unknown parameters.
\vfill

Unless the statistic and parameter are explicitly stated, we will use 
\vfill

In general, the value of the population parameter is unknown. Statistics computed from sampling data can provide information about the unknown parameter.
\vfill

\underline{Common statistics of interest:} Let $y_1,y_2,...,y_n$ be a sample of y-values.
\vfill

- The **sample mean** is $\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i$
\vfill
- The **sample variance** is $s^2 = \frac{1}{n-1} [(y_1-\bar{y})^2 + (y_2-\bar{y})^2 + ...+(y_n-\bar{y})^2]$
		$=\frac{1}{n-1}\sum_{i=1}^n(y_i-\bar{y})^2 = \frac{1}{n-1}\left[\sum y_i^2 - \frac{1}{n}(\sum y_i)^2\right]$
\vfill
	
\newpage
\underline{Common parameters of interest:}

Let t be the population total and $\bar{y}_U$ be the population mean from a population of finite size N. Thus, $t=\sum_{i=1}^N y_i$ and $\bar{y}_u = \frac{1}{N}\sum_{i=1}^N y_i$.
\vfill

- The **population variance** parameter $S^2$ is defined as:
		\begin{eqnarray*}
		S^2 &=& \frac{1}{N-1} \sum_{i=1}^N (y_i - \bar{y}_U)^2\\
		&=& \left(\frac{1}{N-1}\right)\left(\sum_{i=1}^N y_i^2 - \frac{t^2}{N}\right)=\left(\frac{1}{N-1}\right)\left(\sum_{i=1}^N y_i^2 - N \bar{y}_U^2\right)
		\end{eqnarray*}
\vfill

In some textbooks, $\tau, \mu,$ and  $\sigma^2$ are used to represent the population total, mean, and variance.
\vfill

Because only part of the population is sampled in any sampling plan, the value of 
\vfill

The **sampling distribution** of a statistic 
\vfill

The **expected value** of $\hat{\theta}$, denoted $E[\hat{\theta}]$ *is the mean of the sampling distribution of $\hat{\theta}:$ 
	$E[\hat{\theta}]=\sum_\mathcal{S} \hat{\theta}_\mathcal{S} P(\mathcal{S})$*
	\vfill

The **estimation bias** of the estimator $\hat{\theta}$ for estimating a parameter $\theta$ 
\vfill

An estimator $\hat{\theta}$ is unbiased to estimate a parameter $\theta$ if 
\vfill

So far the focus has been on the expected value of a statistic to check for bias. *

\vfill
We will consider two measures of variability: the variance and the mean square error.

\vfill
- The **variance** of the sampling distribution of $\hat{\theta}$ ($V(\hat{\theta})$) is defined to be
	\begin{equation*}
	V(\hat{\theta})=E\left[(\hat{\theta}_\mathcal{S} - E(\hat{\theta})^2\right] = \sum_\mathcal{S} P(\mathcal{S})\left[\hat{\theta}_\mathcal{S}-E(\hat{\theta})\right]^2
	\end{equation*}
	where $\hat{\theta}_\mathcal{S}$ is the value of $\hat{\theta}$ calculated for sample $\mathcal{S}$.
\vfill
- The **mean squared error** is defined to be :
	\begin{equation*}
	MSE[\hat{\theta}]=E\left[(\hat{\theta}-\theta)^2\right] = \sum_\mathcal{S} P(\mathcal{S})\left[(\hat{\theta}_\mathcal{S} - \theta)\right]^2
	\end{equation*}
\vfill

- The MSE, however, can be rewritten as 
	\begin{equation*}
	MSE[\hat{\theta}] = V(\hat{\theta}) + [Bias(\hat{\theta})]^2
	\end{equation*}
	Derivation may be a homework problem.
\newpage

The idea of a sampling distribution is foundational to statistics as a whole.
\vfill

Consider the previous example of taking a SRS of size two from a population of four. Now assume the goal is to estimate the average income of the four units from a sample of size two. Let the salaries be \$80,000, \$120,000, \$60,000, and $10,000.
\vfill
Using the sample mean, what are the possible values for $\theta$?

\vfill
Sketch out the sampling distribution, note: this will be a discrete distribution.

\vfill

Is the SRS unbiased?

\vfill

What is the MSE of this estimator?

\vfill

Now consider a simulation approach





